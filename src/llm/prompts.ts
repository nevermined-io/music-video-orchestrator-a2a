/**
 * Utilities for building prompts for LLM interpretation of user feedback.
 */
import { callLLM } from "./client";
import { Artifact, Message } from "../models/task";

/**
 * Builds a prompt for the LLM to interpret user feedback and suggest the next action.
 * The LLM must return a JSON object: { action: "accept" | "retry" | "modify", newInput?: object }
 * @param {object} params - The context for the LLM
 * @param {Message[]} params.history - The conversation history
 * @param {Artifact[]} params.previousOutput - The previous output/artifact generated
 * @param {Message} params.userComment - The user's feedback or comment
 * @param {any} params.agentCard - The agentCard object describing the agent's skills and output structure
 * @returns {string} The prompt to send to the LLM
 */
export function buildLLMInterpretationPrompt({
  history,
  previousOutput,
  userComment,
  agentCard,
}: {
  history: Message[];
  previousOutput: Artifact[];
  userComment: Message;
  agentCard: any;
}): string {
  const previousOutputStr =
    typeof previousOutput === "string"
      ? previousOutput
      : JSON.stringify(previousOutput, null, 2);
  const agentCardStr = JSON.stringify(agentCard, null, 2);

  return `
You are an orchestration assistant in a multi-agent creative workflow. Your job is to help interpret user feedback and decide the next action for the workflow, based on the conversation history, the agent's output, and the agent's capabilities.

Context:
- The orchestration process involves several agents, each described by an agentCard (see below).
- You will receive the conversation history, the last output generated by the agent, and the user's latest message.
- Your task is to analyze the user's feedback in context and decide if the workflow should continue, repeat the step, or modify the input for the next agent call.

AgentCard (describes the agent's capabilities and expected input/output):
${agentCardStr}

Conversation history:
${JSON.stringify(history, null, 2)}

The agent generated this output:
${previousOutputStr}

The user's message is:
${JSON.stringify(userComment, null, 2)}

Based on the user's feedback, return a JSON object with:
- action: "accept" if the user is satisfied and wants to continue,
- action: "retry" if the user wants to repeat this step,
- action: "modify" if the user wants to change the input (in this case, provide the newInput object, as a synthesis of what the user wants, having in mind the context of the conversation).

Example outputs:
{ "action": "accept" }
{ "action": "retry" }
{ "action": "modify", "newInput": { ... } }

Return ONLY the JSON object, no explanations.
`;
}

/**
 * Interprets user feedback in context using the LLM, returning an action and optionally a new input.
 * @param {object} params - The context for interpretation
 * @param {any} params.previousOutput - The previous output/artifact generated
 * @param {string} params.userComment - The user's feedback or comment
 * @param {any} params.agentCard - The agentCard object describing the agent's skills and output structure
 * @returns {Promise<{ action: "accept" | "retry" | "modify"; newInput?: any }>} The interpreted action and new input if applicable
 */
export async function interpretUserFeedbackWithLLM({
  history,
  previousOutput,
  userComment,
  agentCard,
}: {
  history: Message[];
  previousOutput: Artifact[];
  userComment: Message;
  agentCard: any;
}): Promise<{ action: "accept" | "retry" | "modify"; newInput?: any }> {
  const prompt = buildLLMInterpretationPrompt({
    history,
    previousOutput,
    userComment,
    agentCard,
  });

  const llmResult = await callLLM(prompt, {
    systemPrompt:
      "You are a creative assistant. Return ONLY the JSON object as specified, no explanations.",
    temperature: 0.2,
    maxTokens: 1024,
  });

  const jsonMatch = llmResult.match(/\{[\s\S]*\}/);
  if (!jsonMatch) {
    throw new Error("LLM did not return a valid JSON object: " + llmResult);
  }
  return JSON.parse(jsonMatch[0]);
}
